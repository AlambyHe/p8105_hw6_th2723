---
title: "p8105_hw6_th2723"
author: "Tianhui He"
date: "2019/11/24"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
```

```{r Problem1}
#basic setup
birthweight = read.csv("./data/birthweight.csv")
birthweight = birthweight %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         mrace = as.factor(mrace),
         malform = as.factor(malform))
```
According to what I learned from biostatistical method class, "stepwise" modeling could help us to choose a best model automatically.
```{r}
best_model = step(lm(bwt~., data = birthweight), direction = "backward")
```
This stepwise function gives us the best model using babysex,bhead,blength, delwt,fincome, gaweeks, mheight, mrace, parity, ppwt and smoken as predictors. A brief glance of the 'best model' chosen by R using regression summary. The global p-value shows that it is significant under 0.05 significance level.
```{r}
best_model %>% summary()
```

```{r}
birthweight %>% 
  modelr::add_predictions(best_model) %>% 
  modelr::add_residuals(best_model) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point(alpha = 0.3) + theme_bw() + labs(x = "Fitted Value", y = 'Residuals', title = "Fitted value VS Residuals")
```
```{r}
set.seed(1)
model2 = lm(bwt ~ blength + gaweeks, data = birthweight)
model3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birthweight)

cv_df = 
  modelr::crossv_mc(birthweight, 100)
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
  best_model= map(train, ~lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data =.x)),
  model2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
  model3  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_best_model = map2_dbl(best_model, test, ~ modelr::rmse(model = .x, data = .y)),
         rmse_model2 = map2_dbl(model2, test, ~ modelr::rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(model3, test, ~ modelr::rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
After comparing the violin plot of rmse for the three models, my model using stepwise function has the lowest rmse among three models and thus has least predicted error. It is also reasonable because this model predictor package is automatically chosen by R.

```{r Problem 2}
#basic setup
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```

```{r}
lm(tmax ~ tmin, data = weather_df) %>% 
  broom::tidy() %>% 
  knitr::kable()
```
```{r}
x = weather_df
boot_sample = function(x) {
  sample_frac(x, replace = TRUE)
}#generate boot sample

bootstraps_data = 
  list(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(x))
  ) #Drawing 5000 bootstrap samples

weather_bootstrap = weather_df %>% 
  modelr::bootstrap(n = 5000) 

weather1 = weather_bootstrap %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data =.x)),
    results = map(models, broom::glance)) %>% 
    select(-strap, -models) %>% 
    unnest(results) %>% 
    janitor::clean_names() 
```

```{r}
weather1 %>% 
  ggplot(aes(x = r_squared)) + geom_density(alpha = 0.5) + labs(title = "Distribution of R-square")
```
According to the above graph, r-squared for each strap is nearly normally distributed (bell-shape). However, it is a little left-skewed, implying that there are some extremely high r-squared score that drive the entire distribution to the right.

```{r}
log_info = 
weather_bootstrap%>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data =.x)),
    results = map(models, broom::tidy)) %>% 
    select(-strap, -models) %>% 
    unnest(results) %>% 
   janitor::clean_names() %>% 
   select(id, term, estimate) %>% 
   # spread(key = term, value = estimate)
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  )  %>%
  rename(intercept= '(Intercept)') %>% 
  mutate(log_calc = log(intercept*tmin)) 
```

```{r}
log_info %>% 
  ggplot(aes(x = log_calc)) + geom_density(alpha = 0.5) + labs(title = "Distribution of log(beta0_hat * beta1_hat)")
```
Compared to the distribution of r-squared, we can see that the log(beta0_hat * beta1_hat) estimates are more normally distributed.

95% confidence interval:
```{r}
#for r-square
weather1 %>% 
  pull(r_squared) %>% 
  quantile(., probs = c(0.025, 0.975, 0.95), na.rm = TRUE) %>% 
  knitr::kable()
```

```{r}
#for log(beta0_hat * beta1_hat)
log_info %>% 
  pull(log_calc) %>% 
  quantile(., probs = c(0.025, 0.975, 0.95), na.rm = TRUE) %>% 
  knitr::kable()
```

