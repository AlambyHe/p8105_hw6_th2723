---
title: "p8105_hw6_th2723"
author: "Tianhui He"
date: "2019/11/24"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
```

```{r Problem1}
#basic setup
birthweight = read.csv("./data/birthweight.csv")
birthweight = birthweight %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         mrace = as.factor(mrace),
         malform = as.factor(malform))
```
According to what I learned from biostatistic method class, "stepwise" modeling could help us to choose a best model automatically.
```{r}
best_model = step(lm(bwt~., data = birthweight), direction = "backward")
```
This stepwise function gives us the best model using babysex,bhead,blength, delwt,fincome, gaweeks, mheight, mrace, parity, ppwt and smoken as predictors. A brief glance of the 'best model' chosen by R using regression summary. The global p-value shows that it is significant under 0.05 significance level.
```{r}
best_model %>% summary()
```

```{r}
birthweight %>% 
  modelr::add_predictions(best_model) %>% 
  modelr::add_residuals(best_model) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point(alpha = 0.3) + theme_bw() + labs(x = "Fitted Value", y = 'Residuals', title = "Fitted value VS Residuals")
```
```{r}
set.seed(1)
model2 = lm(bwt ~ blength + gaweeks, data = birthweight)
model3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birthweight)

cv_df = 
  modelr::crossv_mc(birthweight, 100)
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
  best_model= map(train, ~lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data =.x)),
  model2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
  model3  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_best_model = map2_dbl(best_model, test, ~ modelr::rmse(model = .x, data = .y)),
         rmse_model2 = map2_dbl(model2, test, ~ modelr::rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(model3, test, ~ modelr::rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
After comparing the violin plot of rmse for the three models, my model using stepwise function has the lowest rmse among three models and thus has least predicted error. It is also reasonable because this model predictor package is automatically chosen by R.

```{r}

```

